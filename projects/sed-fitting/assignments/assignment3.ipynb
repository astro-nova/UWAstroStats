{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f9a492",
   "metadata": {},
   "source": [
    "# Assignment 3 - SED Fitting\n",
    "\n",
    "## Bayesian Statistics\n",
    "\n",
    "This assignment is split into 3 sections, roughly corresponding to the contents of each of the 3 weeks in the Bayesian Statistics module. \n",
    "\n",
    "All assignments are presented as Jupyter notebooks. You will fork the repository to have your own access to all files. You can edit this notebook directly with your answers and push your changes to GitHub. \n",
    "\n",
    "### **The goal of this assignment is to use different MCMC and Bayesian inference techniques to fit SEDs to galaxy magnitudes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c87cd",
   "metadata": {},
   "source": [
    "# STEP 0 - Prospector Inputs\n",
    "\n",
    "Prospector has some in-built MCMC techniques that you will have used in Assignment 1 (Emcee or Dynesty). For this assignment you will not be using these in-built tools, instead you will use external libraries to code your own MCMC results and perform model comparison on them. We will however still use prospector for the model so lets prepare that here\n",
    "\n",
    "### The model we are using is a very simple parametric model with 6 free parameters\n",
    "\n",
    "* ### $z$ redshift\n",
    "* ### $M_{\\rm star}$ stellar mass\n",
    "* ### $\\log(z_{\\rm sol})$ metallicity?\n",
    "* ### $\\rm dust$ a dust parameter\n",
    "* ### $t_{\\rm age}$ \n",
    "* ### $\\tau$ something\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac4c92",
   "metadata": {},
   "source": [
    "1. Activate the enviroment/kernel you used with prospector installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11fcda",
   "metadata": {},
   "source": [
    "2. Prepare the prospector model (if you like you can edit the below model, but you dont have to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7955b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prospect.models import SedModel, priors\n",
    "from prospect.models.templates import TemplateLibrary\n",
    "from prospect.sources import CSPSpecBasis\n",
    "import time\n",
    "\n",
    "model_params = TemplateLibrary[\"parametric_sfh\"]\n",
    "\n",
    "# Let redshift vary\n",
    "model_params[\"zred\"][\"isfree\"] = True\n",
    "model_params['zred']['init'] = 0.1\n",
    "model_params['zred']['prior'] = priors.TopHat(mini=0,maxi=1)\n",
    "\n",
    "# Build the model\n",
    "prospector_model = SedModel(model_params)\n",
    "\n",
    "sps = CSPSpecBasis(zcontinuous=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e549138",
   "metadata": {},
   "source": [
    "3. Load the data vector for a given galaxy (again you can change the gaalxy if you wish, maybe match one of your galaxies from assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8faa4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sedpy \n",
    "import prospect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "gal_id = 33\n",
    "\n",
    "with fits.open('../data/sw_input.fits') as f:\n",
    "    df = Table(f[1].data).to_pandas()\n",
    "    f.close()\n",
    "\n",
    "def build_obs(gal_id):\n",
    "    \"\"\"Given an object, load in fluxes, convert them to nanomaggies, and create a dict used in Prospector.\"\"\"\n",
    "\n",
    "    inp = {}\n",
    "    \n",
    "    # Get dataframe row for the object\n",
    "    row = df.iloc[gal_id]\n",
    "    inp['redshift'] = row.redshift\n",
    "\n",
    "    # Load the filter response curves from sedpy\n",
    "    bands = [f'sdss_{filt}0' for filt in 'ugriz'] + [f'wise_w{n}' for n in range(1,5)]\n",
    "    filters = sedpy.observate.load_filters(bands)\n",
    "    inp['filters'] = filters\n",
    "    \n",
    "    # Fluxes and uncertainties - already in units of maggies\n",
    "    cols = [f'flux_{filt}' for filt in 'ugriz'] + [f'flux_w{n}' for n in range(1,5)]\n",
    "    fluxes = row[cols].values.astype(float) / 3631\n",
    "\n",
    "    # Errors\n",
    "    cols_err = [f'{col}_e' for col in cols]\n",
    "    errs = row[cols_err].values.astype(float) / 3631\n",
    "\n",
    "    # Anything with a value of 9.999 is null, so may need to mask those fluxes by editing phot_mask\n",
    "    inp['maggies'] = fluxes\n",
    "    inp['maggies_unc'] = errs\n",
    "    inp['phot_mask'] = [True for val in fluxes] # Nothing masked here right now\n",
    "\n",
    "    # This is an array of effective wavelengths for each of the filters.  \n",
    "    # It is not necessary, but it can be useful for plotting so we store it here as a convenience\n",
    "    inp[\"phot_wave\"] = np.array([f.wave_effective for f in inp[\"filters\"]])\n",
    "    inp[\"wavelength\"] = None\n",
    "    \n",
    "    # Populate other fields with default\n",
    "    inp = prospect.utils.obsutils.fix_obs(inp)\n",
    "    return inp\n",
    "\n",
    "obs = build_obs(gal_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5ccdd",
   "metadata": {},
   "source": [
    "4. Prepare a function that takes the 6 parameters as input, and outputs the predicted fluxes in maggies (once this is set up, you shouldn't have to use prospector directly again for this assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88cc5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters should enter the function in this order:\n",
      "['zred' 'mass' 'logzsol' 'dust2' 'tage' 'tau']\n",
      "The first model evaluation took 26.653258085250854s\n",
      "Subsequent evaluations will take 12.884146213531494s\n"
     ]
    }
   ],
   "source": [
    "#a random sample from the prospectors default priors (just to make sure the model runs)\n",
    "random_input_values = np.array([model_params[k]['prior'].sample()[0] for k in model_params.keys() if model_params[k]['isfree']==True])\n",
    "param_names = np.array([model_params[k]['name'] for k in model_params.keys() if model_params[k]['isfree']==True])\n",
    "print('Parameters should enter the function in this order:')\n",
    "print(param_names)\n",
    "\n",
    "#the first model takes longer to run so do that here\n",
    "start = time.time()\n",
    "test_model1 = prospector_model.predict(random_input_values, obs=obs, sps=sps)\n",
    "finish = time.time()\n",
    "print(f'The first model evaluation took {finish-start}s')\n",
    "\n",
    "#future calls should be quick\n",
    "### THIS IS THE FUNCTION YOU CAN USE FOR ALL \n",
    "### YOUR MODEL PREDICTIONS FROM THIS POINT\n",
    "def model(theta):\n",
    "    return prospector_model.predict(theta, obs=obs, sps=sps)\n",
    "\n",
    "# see how long one model prediction takes\n",
    "start = time.time()\n",
    "test_model2 = model(random_input_values*1.2) #change the input params a little here so we know its not just caching outputs\n",
    "finish = time.time()\n",
    "print(f'Subsequent evaluations will take {finish-start}s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cfd0a",
   "metadata": {},
   "source": [
    "# STEP 1 - MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba3bbd9",
   "metadata": {},
   "source": [
    "1. Pick (and install) your 2 favourite MCMC sampling method/implementation you learned about in the lectures (At least 1 of them should be a \"nested\" sampling method, as we will use the features of nested sampling later)\n",
    "\n",
    "Some examples are shown below\n",
    "\n",
    "Metropolis hastings\n",
    "* links \n",
    "\n",
    "Emsemble\n",
    "* Affine-invariant [EMCEE](https://emcee.readthedocs.io/en/stable/)\n",
    "* KDE [Kombine](https://github.com/bfarr/kombine)\n",
    "\n",
    "Nested sampling \n",
    "* Multinest\n",
    "* Polychord\n",
    "* [Nautilus](https://nautilus-sampler.readthedocs.io/en/stable/)\n",
    "* Dynesty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d735709",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431be806",
   "metadata": {},
   "source": [
    "2. Fit your model to your data using your 2 chosen sampling techniques\n",
    "\n",
    "* Choose flat priors for all parameters (you can look at your results from Assignment 1 to get some reasonable ranges) \n",
    "* Plot the resulting parameter constraints on top of each other. e.g. in a corner plot\n",
    "* Do they agree with each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37fee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de26f3",
   "metadata": {},
   "source": [
    "3. Did either of your sampling methods have a burn-in? if so make a plot showing the burn-in and justify how much burn-in to remove. If not, explain why there is no burn-in in your methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce2802b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c435a6",
   "metadata": {},
   "source": [
    "# STEP 2 - Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fd2d0",
   "metadata": {},
   "source": [
    "1. Use the nested sampling technique to compute the Baysian Evidence of your model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4296b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1a48d6",
   "metadata": {},
   "source": [
    "2. Change the model in some-way and re-run your nested sampling chain (e.g. add a new parameter, or dramatically change the prior on a parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c572ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebb326",
   "metadata": {},
   "source": [
    "3. Use a Bayesian model comparison technique to decide which model your data prefer\n",
    "\n",
    "* WE SHOULD CHECK THE SLIDES TO SEE WHICH ONES WILL BE COVERED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe146ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59582ed2",
   "metadata": {},
   "source": [
    "4. How do the conclusions from your \"Bayesian\" model comparison compare to just looking at the change in the best-fit (reduced) chi-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b7702",
   "metadata": {},
   "source": [
    "# STEP 3 - Advanced MCMC techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420060d8",
   "metadata": {},
   "source": [
    "1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
